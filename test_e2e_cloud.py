"""
Teste END-TO-END: Meeting Agent chama DeepResearch na nuvem
Simula o fluxo completo de uma pergunta do usu√°rio at√© a resposta final
Executa: python test_e2e_cloud.py
"""
import asyncio
import os
import sys
from pathlib import Path

# Adicionar path do meeting-agent
sys.path.insert(0, str(Path(__file__).parent))

from agent.integrations.deepresearch_client import (
    DeepResearchClient,
    DeepResearchError,
    DeepResearchTimeoutError
)

async def test_e2e_meeting_to_deepresearch():
    """
    Simula fluxo real: Meeting Agent precisa de pesquisa profunda
    """
    print("üéØ TESTE END-TO-END: Meeting Agent ‚Üí DeepResearch Agent")
    print("="*80)
    
    # Cen√°rio: Usu√°rio faz pergunta complexa no Meeting Agent
    user_query = "Como implementar RAG em sistemas de IA corporativos?"
    
    print(f"\nüë§ USU√ÅRIO PERGUNTA: '{user_query}'")
    print("\nü§ñ Meeting Agent identifica: precisa de pesquisa profunda")
    print("üì° Meeting Agent chama DeepResearch Agent na nuvem...")
    
    # Inicializar cliente (usa DEEPRESEARCH_API_URL do .env)
    client = DeepResearchClient()
    
    try:
        # Verificar disponibilidade
        print("\n1Ô∏è‚É£ Verificando disponibilidade do DeepResearch...")
        health = await client.health_check()
        print(f"   ‚úÖ DeepResearch dispon√≠vel (v{health.get('version')})")
        print(f"   ‚úÖ Model Provider: {health.get('model_provider')}")
        
        # Fazer pesquisa
        print("\n2Ô∏è‚É£ Executando pesquisa profunda...")
        print(f"   üîç Provider: OpenAI GPT-5")
        print(f"   üìä Max steps: 5")
        
        result = await client.research_sync(
            query=user_query,
            model_provider="openai",
            max_steps=5,
            search_provider="tavily"
        )
        
        print(f"\n3Ô∏è‚É£ Pesquisa conclu√≠da!")
        print(f"   ‚è±Ô∏è  Tempo total: {result['metadata']['total_time_seconds']:.1f}s")
        print(f"   üìä Passos executados: {result['metadata']['steps_taken']}")
        print(f"   üìö Fontes coletadas: {len(result.get('sources', []))}")
        print(f"   ‚≠ê Qualidade: {result['metadata']['final_quality_score']}/10")
        
        # Processar resultados
        print("\n4Ô∏è‚É£ Meeting Agent processa resultados...")
        report = result.get('report', '')
        sources = result.get('sources', [])
        
        # Simular cria√ß√£o de fatos estruturados
        facts = []
        for idx, source in enumerate(sources[:10], 1):
            fact = {
                "content": f"Informa√ß√£o relevante sobre RAG da fonte {idx}",
                "source": source,
                "confidence": 0.9,
                "_deepresearch_priority": True,
                "_from_deepresearch": True
            }
            facts.append(fact)
        
        print(f"   ‚úÖ Criados {len(facts)} fatos estruturados")
        
        # Simular resposta final
        print("\n5Ô∏è‚É£ Meeting Agent gera resposta final...")
        final_response = {
            "answer": f"Com base em pesquisa profunda: {report[:200]}...",
            "sources": sources[:5],
            "research_metadata": result['metadata'],
            "structured_facts": facts
        }
        
        print("\n" + "="*80)
        print("‚úÖ TESTE E2E COMPLETO!")
        print("="*80)
        print(f"\nüìä M√âTRICAS:")
        print(f"   ‚Ä¢ Tempo de resposta: {result['metadata']['total_time_seconds']:.1f}s")
        print(f"   ‚Ä¢ Qualidade: {result['metadata']['final_quality_score']}/10")
        print(f"   ‚Ä¢ Fontes: {len(sources)}")
        print(f"   ‚Ä¢ Fatos criados: {len(facts)}")
        
        print(f"\nüìù RESPOSTA FINAL (preview):")
        print("-" * 80)
        print(final_response['answer'])
        print("-" * 80)
        
        print(f"\nüìö TOP 5 FONTES:")
        for idx, source in enumerate(sources[:5], 1):
            print(f"   {idx}. {source}")
        
        # Valida√ß√µes
        assert result['metadata']['model_provider'] == 'openai', "‚ùå Model provider incorreto"
        assert result['metadata']['steps_taken'] > 0, "‚ùå Nenhum passo executado"
        assert len(report) > 500, "‚ùå Report muito curto"
        assert len(sources) > 0, "‚ùå Sem fontes"
        assert len(facts) > 0, "‚ùå Sem fatos estruturados"
        
        print("\n‚úÖ TODAS AS VALIDA√á√ïES PASSARAM!")
        return True
        
    except DeepResearchTimeoutError as e:
        print(f"\n‚è±Ô∏è  TIMEOUT: {e}")
        print("üí° Considere aumentar DEEPRESEARCH_TIMEOUT no .env")
        return False
        
    except DeepResearchError as e:
        print(f"\n‚ùå ERRO NA PESQUISA: {e}")
        return False
        
    except Exception as e:
        print(f"\n‚ùå ERRO INESPERADO: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("üöÄ TESTE E2E - INTEGRA√á√ÉO COMPLETA")
    print("="*80)
    print("")
    
    success = asyncio.run(test_e2e_meeting_to_deepresearch())
    
    print("\n" + "="*80)
    if success:
        print("‚úÖ FLUXO E2E FUNCIONANDO!")
        print("üìå Meeting Agent ‚Üí DeepResearch ‚Üí Resposta = OK")
        print("="*80)
        exit(0)
    else:
        print("‚ùå FLUXO E2E COM PROBLEMAS")
        print("="*80)
        exit(1)
